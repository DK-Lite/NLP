# MRC(기계독해)
정보검색 시스템
document 안에 존내하는 내가 원하는 답변을 가져와 → 진정한 QnA 시스템
## Question Answering?
초기에는 그래프 형태로 질문과 답변을 만든다음에
그래프 매칭을 시켜서 원하는 질문에 답변을 하게 만들었다.
- 문장이 심플하지 못하고 정규화된 형태가 안나옴으로 성능이 좋지 못하다.
- 문서는 찾을수 있지만 문서안에 답을 찾아줄수는 없을까?
### 기계독해의 문제점
정답을 포함하는 문서를 주고 거기다가 질문을 해야한다.
## Paradigms for Question Answering
- IR-based approaches
    - TREC, IBM Watson; Google
정보검색 기반으로 문서를 찾아서 무언갈처리해서 답을 찾음
- Knowledge-based And Hybrid approaches
    - IBM Watson, Apple Siri, Wolfram Alpha
    - True Knowledge Evi
지식 기반이 추가됨, 위키피디아, 자연어로 입력하면 DB에 있는거 가져오면 되지 않을까?
현 QA시스템의 문제점은 답을 주지만 신뢰도가 높지 못하다.(IR)
지식 기반에는 지식이 한정되어 있는 단점(KB)
 Text로 부터 날리지를 생성해서 자동으로 추가하는걸 연구중이다.
## IR-based QA
MRC를 하려면 해당 IR-base 원리를 꼭 이해해야한다.
 - Qustion Processing
    - Query Formulation(명사 동사를 뽑는다.)
    - Answer Type Detection(해당 질문은 어떤 답변 타입을 원하는지를 찾는다)
 - Passage Rtrieval
    - Document Retrieval(질문에 관려있는 문서를 찾는다, 상위 몇개 선택)
    - Passage Retrieval(단락 단위로 자름, 단락을 다시 랭킹화, 거기서 상위 몇개 선택)
 - Answer Processing
    정답위치를 찾아두고 Answer Type Detection을 기반으로 정답을 랭킹화 시키는 곳
## Question Processing
- Answer type Detection(내가 질문한것이 어떤 정답유형을 질문하거나? 알아내는 단계, 누가 세상에서 가장 부자냐?(Person))
- Query Formulation(IR시스템을 넘겨줄 키워드 찾는것, 가장 쉬운방법은 명사 동사 찾아서 넘겨줌)
- Question Type classification(나의 질문이 광범위한 유형을 찾는것, 단답? 서술형? 리스트?)
- Focus Detection(홍길동의 생일은?, 정답에 의해서 바뀌어야 하는지, 정답과 얼마나 유사한지, )
- Relation Extraction(Q에 있는 워드 사이의 관계를 파악, 그래프)
EX)
    What are the two states, you could be reentering if youre crossing Floridas Northern border?
    QT : What
    AT : Location-State
    Query : two states, border, Florida, north
    Focus : the two states
    Relations : borders(Florida, ?x, north)
## Featuers for Passage Ranking
-
## Answer Processing
Passge 에서 후보군을 찾은상태에서 랭킹화 하는단계
    Q : who was Queen victorias second son?
    at : person
### Features for ranking
- Answer type match(답변이 매칭 된게 있느냐?)
- Patten match(ULR, 생일 등 패턴이 맞는지?)
- Question keywords(Query 나온 단어가 주위에 나온단어가 몇개 인가)
- Keyword distance()
- Novelty factor()
- Approsition features(포커스 워드를 찾았으면 그거와 동격관계로 형성하고 있느냐? 야외사장이 누구냐? 사장=누구 는 동격)
- Punctuation location
- Sequences of question terns
### Learning Surface Text Patterns
    1. 질문과 답을 던지고 해당답의 위치를 뚫어두고 주위 문맥의 문장 패턴을 모은다.
    2. 이런 비슷한 패턴이 얼만큼 나왔는지 랭킹화 한다.
    3. 질문이 들어오면 Passge 가 들어오면 패턴을 매칭하고 스코어를 더한다.
    4. 그리고 예측한다.
하지만 MRC에서 Score Attention 에서 다시 부활( 위 패턴을 지가 학습한다. )
컨텍스트 위치(score)로 보고 해당 위치가 답이다라고 알수있게됨
Embedding Vector가 존재하기때문에 비슷한 단어가 나와도 유추해낼수 있지만
위의 방법은 전혀 다른 단어로 인식하기 때문에 성능이 좋지 못하다(호텔 != 모텔)
### SOTA in TREC-9
## KB(Knowedge-based) QA
위키피디아 Info Box를 DB화
s-p-o(주어-관계-답) 형태의 그래프로 다 이루어짐
    born-in("Goldman", "June 27 1869) P(S, O)
문제점
- Entity Grounding
    - whose granddaughte starred in E.T.?
    - KB형태로 그대로 들어가 있다고 장담할수없음( 애플 )
- Reasoning
    - acted-in ?x "E.T", granddaughter-of ?x ?y
# Machine Reading Comprehension
주어진 문서를 기계가 이해하고 관련 질문을 답변해주는 시스템
IR, KB 방식은 Feature를 찾는과정이 어려움으로 그것을 머신러닝으로 해결하자
1. 기계가 글과 질문을 읽고
2. 추론을 하여(답이 나올만한 패턴을 학습)
3. 글에서 정답을 찾아주는것(위치)
## Bidirectional Attention Flow(Seo et al., 2017) - 서민준(네이버)
1. 문서의 단어와 질문의 단어를 가져와서,
2. Glove, char-CNN(oov 문제를 위해서 Char로 쪼개서 임베딩)
3. Bi-Directional RNN (문맥을 파악)
4. Co Attention Layer, Q2A, C2Q 두개의 Attention사용( 문서와 질문의 각 단어들간의 연관성을 학습)
5.
## R-Net()
Self-Attention 이 추가됨
### 공통적인 구조
- Encoding Layer
    - Word Embedding
        - CBOW
        - Skip-gram
        - fastText(oov문제때문에 N-Gram으로 묶음, Prediction model)
        - GloVe : 서로 다른 문장에서 단어의 연관이 나타날수 있기때문에, 확률모델, 내적값이 확률값이 되도록 학습(두단어가 동시에 등장할)
        - CoVe : 문맥을 반영,
        - ELMo : 문맥을 반영, Language Model, 단어를 예측하는 모델로 학습, 중의어에 대해서 해결
Word2Vector에서 In-Vector를 가지고
In-Vecotr를 검색하면  : 비슷한 단어가 나온다
Out-Vector를 검색하면 :주변의 자주 나오는 문맥이 나온다.
IR 단어검색에서 문서나 안나오면 유사도를 넣을텐데 단어 유사도 보단 문맥적인 유사도도 MRC에선 필요하다.
EX)
    "메시가 결장한 이유는?"
    보통 메시만 매칭이 됨, 메시가 누구와의 경기에서 아킬레스건을 다쳐서 뛰지 못한다.(결장이라는 단어가 없음)
    문맥으로 확장해서 결장이 위 문장과 연관이 있다고 찾아야한다.
    In-Vector : 결장
    Out-Vecotr : 아킬레스건, 염좌, ...
- Co-Attention Layer
    - 질문에서의 단어가 문서에서 어떤 단어가 가장 연관성이 있는지를 찾아낸다.
    - 그래서 문맥적인 부분이 반영되서 수치화된다(비슷한 단어가 들어와도 벡터성으로 계산 되기에 적합)
    - Bidirectional Attention
        - Context2Query : 문서의 단어가 쿼리에 있는단어와 얼마나 연관이 있는지 확률이 나옴
        - Query2Context : 질문의 단어가 문서에 있는 단어와 얼마나 연관이 있는지 확률이 나옴
        - Modeling Layer 에서는 위 두 벡터들을 이용해서 단어의 임베딩화를 시켜주는데 이때 중의성 문제를 해소하기 위해 Bidirectional 을 이용
    - Self-Attention : 자기 자신을 기준으로 주위 Attention을 구함
        - bidirectional LSTM 은 Long Defendency 문제가 있다.
        - Long defendency 문제 해결, 개체명 인식이나 형태소 분석에 유리
- Output Layer
    - Start : Ouput은 T개의 노드중에서 One-hot vector로 표현
    - End : Start를 받아서 똑같이 동작
### Pointer Networds(Seq2SEq)
- Encoder - Decoder
- Decoder의 Output은 Encoder의 어디를 가르켜야하는지 위치를 찍어줌
- MRC는 Start, End 라서 Decoder의 크기는 2개 이고 각각이 Encoder의 위치를 가르키고 있다.
- 루엉 어텐션에서 Attention Vector를 안만들고 Softmax이후 가장 큰값을 가르키게 하는 방식도 있음
## FAQ 분류
여행사나 쇼핑몰 등에서 질문이 들어오면 준비된 FAQ를 Classificaion으로 분류해서 보여준다.
어휘 불일치 문제가 많이 나온다. 문서는 문서에 단어가 워낙 많아서 검색이 되는데 FAQ는 질문자체가 한문장이라서 필요한 단어가 안나타날 확률이 높다.
사용자 : "에어컨에서 물이 세요"
FAQ : "에어컨 누수현상"
위와 같은 예시로 그냥 검색하면 안된다.
1. 사용자들의 입력이 구어체고 통신체다.
2. GloVe, Word Embedding 두개를 입력으로 넣는데 원래 의미를 가지는 Embedding은 Fine tuning 하지 않음
3. 자소로 나눠서 학습을 시킴 ("안대여")
## Transformer & BERT
Multi-Head Attention
- 하는 이유는?
- 200차원 전체를 가지고 soft max , 100차원 의 softmax를 하면 100차원의 정보가 더 많이 살아남는다.
- 작은 범위에서 softmax는 뚜렷한 특징만 살아남는 효과
- 다양한 관점에서 문장을 바라보는 효과